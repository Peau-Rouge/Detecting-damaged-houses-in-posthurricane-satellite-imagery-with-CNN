{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import sys\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport os\nfrom skimage.io import imread as imread\nfrom PIL import Image\nimport imageio\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom pylab import rcParams\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.metrics import balanced_accuracy_score\nfrom sklearn import metrics\n\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model, load_model\nfrom keras import optimizers, losses, activations, models\n\nfrom keras.layers import Input, Dropout, concatenate, GlobalAveragePooling2D\n#from keras.layers.core import Lambda, RepeatVector, Reshape\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\n#from keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras import backend as K\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Flatten\nfrom keras import applications\nfrom keras.applications import resnet50\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -lha ../input/satellite-images-of-hurricane-damage\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -lha ../input/maposm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_path = '../input/satellite-images-of-hurricane-damage/'\n\ndef print_file_sizes(input_path, subset):\n    print('{}:'.format(subset))\n    print('')\n    path = input_path + subset + '/'\n    for f in os.listdir(path):\n        if not os.path.isdir(path + f):\n            print(f.ljust(30) + str(round(os.path.getsize(path + f) / 1000000, 2)) + 'MB')\n        else:\n            sizes = [os.path.getsize(path+f+'/'+x)/1000000 for x in os.listdir(path + f)]\n            print(f.ljust(30) + str(round(sum(sizes), 2)) + 'MB' + ' ({} files)'.format(len(sizes)))\n    print('')\n    \nprint_file_sizes(input_path, 'train_another')\nprint_file_sizes(input_path, 'validation_another')\nprint_file_sizes(input_path, 'test_another')\nprint_file_sizes(input_path, 'test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\nsatellite_dir = Path('../input/satellite-images-of-hurricane-damage/')\nimage_df = pd.DataFrame({'path': list(satellite_dir.glob('**/*.jp*g'))})\nimage_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_df['damage'] = image_df['path'].map(lambda x: x.parent.stem)\nimage_df['data_split'] = image_df['path'].map(lambda x: x.parent.parent.stem)\nimage_df['location'] = image_df['path'].map(lambda x: x.stem)\nimage_df['lat'] = image_df['location'].map(lambda x: float(x.split('_')[-1]))\nimage_df['lon'] = image_df['location'].map(lambda x: float(x.split('_')[0]))\nimage_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_df = image_df.drop(columns=['path', 'location', 'data_split'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_df.to_csv('lonlat_houston.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\nfor c_group, c_rows in image_df.groupby(['damage']):\n    ax1.plot(c_rows['lat'], c_rows['lon'], '.', label=c_group, alpha=0.5)\nax1.legend()\nax1.set_title('Data by Damage Type')\nfor c_group, c_rows in image_df.groupby(['data_split']):\n    ax2.plot(c_rows['lat'], c_rows['lon'], '.', label=c_group, alpha=0.5)\nax2.legend()\nax2.set_title('Data by Group')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BBox = ((image_df.lon.min(),image_df.lon.max(),image_df.lat.min(), image_df.lat.max()))\nBBox","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ruh_m = plt.imread('../input/maposm/map (1).png')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (15,12))\nfor c_group, c_rows in image_df.groupby(['damage']):\n    #ax.plot(c_rows['lon'], c_rows['lat'], '.', label=c_group, alpha=0.5)\n    ax.scatter(c_rows['lon'], c_rows['lat'], label=c_group, alpha= 0.5)\nax.legend()\nax.set_title('Data by Damage Type')\n\nax.set_xlim(BBox[0],BBox[1])\nax.set_ylim(BBox[2],BBox[3])\nax.imshow(ruh_m, zorder=0, extent = BBox, aspect= 'equal')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading Train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_path_damage = input_path + 'train_another/damage/'\nimage_path_nodamage = input_path + 'train_another/no_damage/'\n\nimage_list_damage = os.listdir(image_path_damage)\nimage_list_damage = [img for img in image_list_damage if not img.startswith('.')] # removing files starting with '.'\n\nimage_list_nodamage = os.listdir(image_path_nodamage)\nimage_list_nodamage = [img for img in image_list_nodamage if not img.startswith('.')] # removing files starting with '.'\n\n\nlen(image_list_damage), len(image_list_nodamage)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N = 4\n\nimg = imageio.imread(image_path_damage + image_list_damage[N])\nimg2 = imageio.imread(image_path_damage + image_list_damage[N+1])\nimg3 = imageio.imread(image_path_damage + image_list_damage[N+2])\n\nfig, arr = plt.subplots(1, 3, figsize=(15, 10))\narr[0].imshow(img)\narr[0].set_title('Damage')\narr[1].imshow(img2)\narr[1].set_title('Another Damage')\narr[2].imshow(img3)\narr[2].set_title('Another Damage')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N = 145\nimg = imageio.imread(image_path_nodamage + image_list_nodamage[N])\nimg2 = imageio.imread(image_path_nodamage + image_list_nodamage[N+1])\nimg3 = imageio.imread(image_path_nodamage + image_list_nodamage[N+2])\n\nfig, arr = plt.subplots(1, 3, figsize=(15, 10))\narr[0].imshow(img)\narr[0].set_title('No Damage')\narr[1].imshow(img2)\narr[1].set_title('Another No Damage')\narr[2].imshow(img3)\narr[2].set_title('Another No Damage')\n\nplt.savefig('/kaggle/working/damage.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img.shape\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ## Plotting RGB bands"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=5, ncols=3, sharex=True, sharey=True, figsize=(8,10))\n\ni = 0\n\nfor image in [img, img2, img3]:\n    ax[0,i].imshow(image[:,:,0], cmap='Reds')\n    ax[0,i].set_title('{} - {}'.format('No Damage'+str(i), 'R'))\n    ax[1,i].imshow(image[:,:,1], cmap='Greens')\n    ax[1,i].set_title('{} - {}'.format('No Damage'+str(i), 'G'))\n    ax[2,i].imshow(image[:,:,2], cmap='Blues')\n    ax[2,i].set_title('{} - {}'.format('No Damage'+str(i), 'B'))\n    ax[3,i].imshow(image[:,:,2], cmap='Greys_r')\n    ax[3,i].set_title('{} - {}'.format('No Damage'+str(i), 'IR'))\n    ax[4,i].imshow(image)\n    ax[4,i].set_title('{} - {}'.format('No Damage'+str(i), 'RGB'))\n    \n    i = i+1\n    \nplt.savefig('/kaggle/working/RGB_noDamage.png', bbox_inches='tight')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subset = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len_images = len(image_list_damage)\nIMG_CHANNELS = 3\nIMG_HEIGHT, IMG_WIDTH = 128, 128\n\n\nif subset:\n\n    X_train = np.zeros((4000, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n\n    y_train = np.zeros((4000, 1), dtype=np.uint8)\n    \n    for n in range(0, 2000):\n    #for n in range(len_images):\n\n        filepath_damage = image_path_damage + image_list_damage[n]\n\n        if filepath_damage.split('.')[-1] == 'jpeg':\n\n            #print(filename)\n            img = imageio.imread(filepath_damage)\n            X_train[n] = img\n            y_train[n] = 1\n\n        filepath_nodamage = image_path_nodamage + image_list_nodamage[n]\n\n        if filepath_nodamage.split('.')[-1] == 'jpeg':\n\n            #print(filename)\n            img = imageio.imread(filepath_nodamage)\n            X_train[2000 + n] = img\n            y_train[2000 + n] = 0\n\nelse:\n    \n    X_train = np.zeros((len_images*2, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n\n    y_train = np.zeros((len_images*2, 1), dtype=np.uint8)\n\n    \n    for n in range(len_images):\n\n        filepath_damage = image_path_damage + image_list_damage[n]\n\n        if filepath_damage.split('.')[-1] == 'jpeg':\n\n            #print(filename)\n            img = imageio.imread(filepath_damage)\n            X_train[n] = img\n            y_train[n] = 1\n\n        filepath_nodamage = image_path_nodamage + image_list_nodamage[n]\n\n        if filepath_nodamage.split('.')[-1] == 'jpeg':\n\n            #print(filename)\n            img = imageio.imread(filepath_nodamage)\n            X_train[5000 + n] = img\n            y_train[5000 + n] = 0\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_list = [i for u in y_train for i in u]\npd.Series(y_train_list).value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Validation data"},{"metadata":{"trusted":true},"cell_type":"code","source":"val_damage = input_path + 'validation_another/damage/'\nval_nodamage = input_path + 'validation_another/no_damage/'\n\nval_list_damage = os.listdir(val_damage)\nval_list_damage = [img for img in val_list_damage if not img.startswith('.')] # removing files starting with '.'\n\nval_list_nodamage = os.listdir(val_nodamage)\nval_list_nodamage = [img for img in val_list_nodamage if not img.startswith('.')] # removing files starting with '.'\n\n\nlen(val_list_damage), len(val_list_nodamage)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_val = imageio.imread(val_damage + val_list_damage[0])\nimg_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len_images = len(val_list_damage)\nIMG_CHANNELS = 3\nIMG_HEIGHT, IMG_WIDTH = 128, 128\n\n\n\nif subset:\n\n    X_val = np.zeros((len_images, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n    y_val = np.zeros((len_images, 1), dtype=np.uint8)\n    \n    for n in range(500):\n\n        filepath_damage = val_damage + val_list_damage[n]\n\n        if filepath_damage.split('.')[-1] == 'jpeg':\n\n            #print(filename)\n            img = imageio.imread(filepath_damage)\n            X_val[n] = img\n            y_val[n] = 1\n\n        filepath_nodamage = val_nodamage + val_list_nodamage[n]\n\n        if filepath_nodamage.split('.')[-1] == 'jpeg':\n\n            #print(filename)\n            img = imageio.imread(filepath_nodamage)\n            X_val[500 + n] = img\n            y_val[500 + n] = 0\n    \nelse:\n    \n    X_val = np.zeros((2000, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n    y_val = np.zeros((2000, 1), dtype=np.uint8)\n\n    \n    for n in range(1000):\n\n        filepath_damage = val_damage + val_list_damage[n]\n\n        if filepath_damage.split('.')[-1] == 'jpeg':\n\n            #print(filename)\n            img = imageio.imread(filepath_damage)\n            X_val[n] = img\n            y_val[n] = 1\n\n        filepath_nodamage = val_nodamage + val_list_nodamage[n]\n\n        if filepath_nodamage.split('.')[-1] == 'jpeg':\n\n            #print(filename)\n            img = imageio.imread(filepath_nodamage)\n            X_val[1000 + n] = img\n            y_val[1000 + n] = 0\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_val.shape, y_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_val_list = [i for u in y_val for i in u]\npd.Series(y_val_list).value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test data"},{"metadata":{},"cell_type":"markdown","source":"\n> test_another:\n\n> damage                        20.12MB (8000 files)\n\n> no_damage                     3.01MB (1000 files)"},{"metadata":{"trusted":true},"cell_type":"code","source":"Balanced = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nif Balanced:\n    test_damage = input_path + 'test_another/damage/'\n    test_nodamage = input_path + 'test_another/no_damage/'\n\n    test_list_damage = os.listdir(test_damage)\n    test_list_damage = [img for img in test_list_damage if not img.startswith('.')] # removing files starting with '.'\n\n    test_list_nodamage = os.listdir(test_nodamage)\n    test_list_nodamage = [img for img in test_list_nodamage if not img.startswith('.')] # removing files starting with '.'\n\n\nelse:\n    test_damage = input_path + 'test/damage/'\n    test_nodamage = input_path + 'test/no_damage/'\n\n    test_list_damage = os.listdir(test_damage)\n    test_list_damage = [img for img in test_list_damage if not img.startswith('.')] # removing files starting with '.'\n\n    test_list_nodamage = os.listdir(test_nodamage)\n    test_list_nodamage = [img for img in test_list_nodamage if not img.startswith('.')] # removing files starting with '.'\n\n\nlen(test_list_damage), len(test_list_nodamage)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_test = imageio.imread(test_damage + test_list_damage[0])\nimg_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len_images = len(test_list_damage)\nIMG_CHANNELS = 3\nIMG_HEIGHT, IMG_WIDTH = 128, 128\n\n\n\nif Balanced:\n\n    X_test = np.zeros((9000, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n    y_test = np.zeros((9000, 1), dtype=np.uint8)\n    \n    for n in range(8000):\n\n        filepath_damage = test_damage + test_list_damage[n]\n\n        if filepath_damage.split('.')[-1] == 'jpeg':\n\n            #print(filename)\n            img = imageio.imread(filepath_damage)\n            X_test[n] = img\n            y_test[n] = 1\n            \n    for n in range(1000):\n        filepath_nodamage = test_nodamage + test_list_nodamage[n]\n\n        if filepath_nodamage.split('.')[-1] == 'jpeg':\n\n            #print(filename)\n            img = imageio.imread(filepath_nodamage)\n            X_test[8000 + n] = img\n            y_test[8000 + n] = 0\n    \nelse:\n    \n    X_test = np.zeros((2000, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n    y_test = np.zeros((2000, 1), dtype=np.uint8)\n\n    \n    for n in range(1000):\n\n        filepath_damage = test_damage + test_list_damage[n]\n\n        if filepath_damage.split('.')[-1] == 'jpeg':\n\n            #print(filename)\n            img = imageio.imread(filepath_damage)\n            X_test[n] = img\n            y_test[n] = 1\n\n        filepath_nodamage = test_nodamage + test_list_nodamage[n]\n\n        if filepath_nodamage.split('.')[-1] == 'jpeg':\n\n            #print(filename)\n            img = imageio.imread(filepath_nodamage)\n            X_test[1000 + n] = img\n            y_test[1000 + n] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_list = [i for u in y_test for i in u]\npd.Series(y_test_list).value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data augmentation & Normalization of data with ImageDataGenerator"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n        rescale=1./255,\n        rotation_range=45,\n        shear_range=0.2,\n        zoom_range=0.5,\n        horizontal_flip=True,\n        vertical_flip=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_datagen = ImageDataGenerator(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Batch processing - Flow from Directory"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes=2\ny_train_categorize = to_categorical(y_train, num_classes)\ny_test_categorize = to_categorical(y_test, num_classes)\ny_val_categorize = to_categorical(y_val, num_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow(X_train, y_train_categorize, batch_size=32, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator = test_datagen.flow(X_test, y_test_categorize, batch_size=1, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_generator = test_datagen.flow(X_val, y_val_categorize, batch_size=32, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape, y_train_categorize.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.shape, y_test_categorize.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_val.shape, y_val_categorize.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nSTEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\nSTEP_SIZE_TEST=test_generator.n//test_generator.batch_size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PART 1: Custom model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_new = Sequential([\n    Conv2D(32, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH,3)),\n    MaxPooling2D(pool_size=(2, 2)),\n    \n    # new\n    Conv2D(32, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH,3)),\n    MaxPooling2D(pool_size=(2, 2)),\n    # end\n    \n    Dropout(0.2),\n    Conv2D(64, 3, padding='same', activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    Conv2D(128, 3, padding='same', activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    Dropout(0.2),\n    Flatten(),\n    Dense(256, activation='relu'),\n    Dense(128, activation='relu'),\n    Dense(num_classes, activation='softmax')\n])\n\n# load weights\n#model_new.load_weights(\"/kaggle/working/Custom_weights.best.hdf5\")\n\n# compile\nmodel_new.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel_new.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(model_new.layers)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Fit model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# checkpoint\nfilepath=\"/kaggle/working/Custom_weights.best.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]\n\n# Fit the model\nnew_history = model_new.fit_generator(\n            train_generator,\n            steps_per_epoch=STEP_SIZE_TRAIN,\n            epochs=75,\n            validation_data=validation_generator,\n            validation_steps=STEP_SIZE_VALID,\n            callbacks=callbacks_list)\n\n#model_new.save('/kaggle/working/hurricane-model-withDropouts-40epochs.h5')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reloading best weights"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load weights\nmodel_new.load_weights(\"/kaggle/working/Custom_weights.best.hdf5\")\n# Compile model (required to make predictions)\nmodel_new.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nprint(\"Created model and loaded weights from file\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"> ### Learning curves"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1, figsize = (7,9)) \n    \nplt.subplot(211)  \nplt.plot(new_history.history['accuracy'])  \nplt.plot(new_history.history['val_accuracy'])  \nplt.title('model accuracy with Custom model')  \nplt.ylabel('accuracy')  \nplt.xlabel('epoch')  \nplt.ylim(0.3,1)\nplt.legend(['train', 'valid']) \n#plt.grid(ls='--', c='C7')\n   \nplt.subplot(212)  \nplt.plot(new_history.history['loss'])  \nplt.plot(new_history.history['val_loss'])  \nplt.title('model loss with Custom model')  \nplt.ylabel('loss')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'valid']) \n#plt.grid(ls='--', c='C7')\n\nplt.savefig('/kaggle/working/model_hurricane_Custom_45epochs.png', bbox_inches='tight')\n\n# list all data in some_old_history\n#print(history.some_old_history.keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(test_generator)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Making predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model_new.predict_generator(test_generator,steps = STEP_SIZE_TEST)\npredictions[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicts = np.argmax(predictions, axis=1)\npd.Series(predicts).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true = [z for y in y_test for z in y]\npd.Series(y_true).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicts = pd.Series(predicts)\ny_true = pd.Series(y_true)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Some metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Model Custom after 45 epochs \\n\")\nprint(\"Precision\", precision_score(y_true, predicts, average=None), '\\n')\nprint(\"Recall\", recall_score(y_true, predicts, average=None), '\\n')\nprint(\"f1_score\", f1_score(y_true, predicts, average=None), '\\n')\nprint(\"confusion_matrix\")\nprint(confusion_matrix(y_true, predicts))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix = confusion_matrix(y_true, predicts)\ndf_cm = pd.DataFrame(matrix, \n  index = ['Not damaged', 'Flooded'],\n  columns = ['Not damaged', 'Flooded'])\n\nsns.heatmap(df_cm,annot=True,cbar=False, fmt='g', square=True)\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.title('Confusion Matrix of Custom CNN')\n\n#plt.figure(figsize = (4,7))\n#plt.show()\nplt.savefig('/kaggle/working/confusion_matrix_Custom.png', bbox_inches='tight')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_loss, val_accuracy = model_new.evaluate(validation_generator)\ntest_loss, test_accuracy = model_new.evaluate(test_generator)\n\nval_accuracy, test_accuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Transfer Learning"},{"metadata":{},"cell_type":"markdown","source":"Transfer Learning via fine-tuning\n\n* removing the fully-connected layers of an existing network, placing a new set of fully-connected layers on top of the network, and then fine-tuning these weights (and optionally previous layers) to recognize the new object classes\n* this technique is usually recommended when the training dataset is large and very similar to the original dataset that the pre-trained model was trained on"},{"metadata":{},"cell_type":"markdown","source":"## VGG16"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# create the base model from the pre-trained model VGG16\n# note that, if using a Kaggle server, internet has to be turned on\nweights_used = True\n\n\nif weights_used:\n    pretrained_model = tf.keras.applications.vgg16.VGG16(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n                                                         include_top=False,\n                                                         weights='imagenet')\nelse:\n    pretrained_model = tf.keras.applications.vgg16.VGG16(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n                                                         include_top=False,\n                                                         weights= None)\n# freeze the convolutional base\npretrained_model.trainable = False\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pretrained_model converts each 128x128x3 image to a 4x4x512 block of features. \n\npretrained_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(pretrained_model.layers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Average over the 4x4 spatial locations to convert the block of features into a single 512-element vector per image:\n\nglobal_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n# set the initializers with a seed for reproducible behaviour\nprediction_layer = tf.keras.layers.Dense(2,kernel_initializer=tf.keras.initializers.GlorotUniform(seed=1992),\n                                         bias_initializer=tf.keras.initializers.GlorotUniform(seed=1992))\n#Now stack all the components using a tf.keras.Sequential model:\n\nvgg_model = tf.keras.Sequential([pretrained_model,\n                             global_average_layer,\n                             prediction_layer])\n\nbase_learning_rate = 0.0001\nvgg_model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nvgg_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(vgg_model.layers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nvgg_history = vgg_model.fit_generator(\n            train_generator,\n            steps_per_epoch=STEP_SIZE_TRAIN,\n            epochs=15,\n            validation_data=validation_generator,\n            validation_steps=STEP_SIZE_VALID)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1, figsize = (6,10)) \n    \nplt.subplot(211)  \nplt.plot(vgg_history.history['accuracy'])  \nplt.plot(vgg_history.history['val_accuracy'])  \nplt.title('model accuracy with vgg16 before fine-tuning')  \nplt.ylabel('accuracy')  \nplt.xlabel('epoch')\nplt.ylim(0.3,1)\nplt.legend(['train', 'valid']) \n    \nplt.subplot(212)  \nplt.plot(vgg_history.history['loss'])  \nplt.plot(vgg_history.history['val_loss'])  \nplt.title('model loss with vgg16 before fine-tuning')  \nplt.ylabel('loss')  \nplt.xlabel('epoch')\nplt.legend(['train', 'valid']) \n\nplt.savefig('/kaggle/working/model_hurricane_vgg16_before_15epochs.png', bbox_inches='tight')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Some notes from the TensorFlow tutorial on transfer learning:\n\n> Now fine-tune the weights of the top layers of the pre-trained model alongside the training of the classifier you added. The training process will force the weights to be tuned from generic features maps to features associated specifically to our dataset. This should only be attempted after you have trained the top-level classifier with the pre-trained model set to non-trainable. If you add a randomly initialized classifier on top of a pre-trained model and attempt to train all layers jointly, the magnitude of the gradient updates will be too large (due to the random weights from the classifier) and your pre-trained model will forget what it has learned. Only a small number of top layers of the pre-trained model should be fine-tuned. In most convolutional networks, the higher up a layer is, the more specialized it is. The first few layers learn very simple and generic features which generalize to almost all types of images. As you go higher up, the features are increasingly more specific to the dataset on which the model was trained. The goal of fine-tuning is to adapt these specialized features to work with the new dataset, rather than overwrite the generic learning."},{"metadata":{"trusted":true},"cell_type":"code","source":"# unfreeze the layers\npretrained_model.trainable = True\n\n# let's take a look to see how many layers are in the base model\nprint(\"Number of layers in the pre-trained model: \", len(pretrained_model.layers))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fine-tune from this layer onwards\nfine_tune_at = 15\n\n# freeze all the layers before the `fine_tune_at` layer\nfor layer in pretrained_model.layers[:fine_tune_at]:\n  layer.trainable =  False\n\n#Recompile the model using a lower training rate:\n\nvgg_model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate/15),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nvgg_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(vgg_model.trainable_variables)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fine_tune_epochs = 60\ninitial_epochs = 15\ntotal_epochs =  initial_epochs + fine_tune_epochs\n\n\n# checkpoint\nfilepath=\"/kaggle/working/VGG_weights.best.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]\n\nvgg_history_final = vgg_model.fit_generator(\n            train_generator,\n            epochs=total_epochs,\n            initial_epoch=vgg_history.epoch[-1]+1,\n            validation_data=validation_generator,\n            validation_steps=STEP_SIZE_VALID,\n            callbacks=callbacks_list)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading best weights"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load weights\nvgg_model.load_weights(\"/kaggle/working/VGG_weights.best.hdf5\")\n# Compile model (required to make predictions)\nvgg_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nprint(\"Created model and loaded weights from file\")\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Learning curves"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1, figsize = (7,10)) \n    \nplt.subplot(211)  \nplt.plot(vgg_history.history['accuracy']+vgg_history_final.history['accuracy']) \nplt.plot(vgg_history.history['val_accuracy']+vgg_history_final.history['val_accuracy'])  \nplt.title('model accuracy with vgg16 after fine-tuning')  \nplt.ylabel('accuracy')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'valid']) \nplt.ylim(0.3,1)\nplt.axvline(initial_epochs, c='C7', ls='--')\n\nplt.subplot(212)  \nplt.plot(vgg_history.history['loss']+vgg_history_final.history['loss'])  \nplt.plot(vgg_history.history['val_loss']+vgg_history_final.history['val_loss'])  \nplt.title('model loss with vgg16 after fine-tuning')  \nplt.ylabel('loss')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'valid']) \nplt.axvline(initial_epochs, c='C7', ls='--')\n\nplt.savefig('/kaggle/working/model_hurricane_vgg16_after_45epochs.png', bbox_inches='tight')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Making predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = vgg_model.predict_generator(test_generator,steps = STEP_SIZE_TEST)\npredictions[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicts = np.argmax(predictions, axis=1)\npd.Series(predicts).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true = [z for y in y_test for z in y]\npd.Series(y_true).value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"predicts = pd.Series(predicts)\ny_true = pd.Series(y_true)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Model VGG fine-tuned \\n\")\nprint(\"Precision\", precision_score(y_true, predicts, average=None), '\\n')\nprint(\"Recall\", recall_score(y_true, predicts, average=None), '\\n')\nprint(\"f1_score\", f1_score(y_true, predicts, average=None), '\\n')\nprint(\"confusion_matrix\")\nprint(confusion_matrix(y_true, predicts))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix = confusion_matrix(y_true, predicts)\ndf_cm = pd.DataFrame(matrix, \n  index = ['Not damaged', 'Flooded'],\n  columns = ['Not damaged', 'Flooded'])\n\nsns.heatmap(df_cm,annot=True,cbar=False, fmt='g', square=True)\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.title('Confusion Matrix of VGG16 CNN')\n\n#plt.figure(figsize = (4,7))\n#plt.show()\nplt.savefig('/kaggle/working/confusion_matrix_vgg16.png', bbox_inches='tight')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_loss, val_accuracy = vgg_model.evaluate(validation_generator)\ntest_loss, test_accuracy = vgg_model.evaluate(test_generator)\n\nval_accuracy, test_accuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ResNet50"},{"metadata":{},"cell_type":"markdown","source":"> Tweaking it a bit adding Dropouts "},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet_model = resnet50.ResNet50(include_top = False, pooling = 'avg', weights='imagenet')\n# freeze the convolutional base\nresnet_model.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(resnet_model.layers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res_model = Sequential()\n\nres_model.add(resnet_model)\nres_model.add(Dense(1024,activation='relu')) #dense layer 2\nres_model.add(Dropout(0.2))\nres_model.add(Dense(128, activation='relu'))\nres_model.add(Dropout(0.5))\nres_model.add(Dense(num_classes, activation = 'softmax'))\n\nbase_learning_rate = 0.0001\nres_model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nres_model.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(res_model.layers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res_history = res_model.fit_generator(\n            train_generator,\n            steps_per_epoch=STEP_SIZE_TRAIN,\n            epochs=10,\n            validation_data=validation_generator,\n            validation_steps=STEP_SIZE_VALID)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1, figsize = (6,10)) \n    \nplt.subplot(211)  \nplt.plot(res_history.history['accuracy'])  \nplt.plot(res_history.history['val_accuracy'])  \nplt.title('model accuracy with ResNet50 before fine-tuning')  \nplt.ylabel('accuracy')  \nplt.xlabel('epoch')\nplt.ylim(0.3,1)\nplt.legend(['train', 'valid']) \n    \nplt.subplot(212)  \nplt.plot(res_history.history['loss'])  \nplt.plot(res_history.history['val_loss'])  \nplt.title('model loss with ResNet50 before fine-tuning')  \nplt.ylabel('loss')  \nplt.xlabel('epoch')\nplt.legend(['train', 'valid']) \n\nplt.savefig('/kaggle/working/model_hurricane_resnet50_before_15epochs.png', bbox_inches='tight')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# unfreeze the layers\nresnet_model.trainable = True\n\n# let's take a look to see how many layers are in the base model\nprint(\"Number of layers in the pre-trained model: \", len(resnet_model.layers))\n\n# fine-tune from this layer onwards\nfine_tune_at = 10\n\n# freeze all the layers before the `fine_tune_at` layer\nfor layer in resnet_model.layers[:fine_tune_at]:\n  layer.trainable =  False\n\n#Recompile the model using a lower training rate:\n\nres_model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate/10),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nres_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#len(res_model.trainable_variables)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"initial_epochs = 10\nfine_tune_epochs = 65\ntotal_epochs =  initial_epochs + fine_tune_epochs\n\n# checkpoint\nfilepath=\"/kaggle/working/ResNet50_weights.best.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]\n\n\nres_history_final = res_model.fit_generator(\n            train_generator,\n            epochs=total_epochs,\n            initial_epoch=res_history.epoch[-1]+1,\n            validation_data=validation_generator,\n            validation_steps=STEP_SIZE_VALID,\n            callbacks=callbacks_list)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Loading weights"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_path = '../input/resnet50-weights/'\n\nfor f in os.listdir(input_path):\n    print(f)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load weights\nres_model.load_weights(\"../input/resnet50-weights/ResNet50_weights.best.hdf5\")\n\n# Compile model (required to make predictions)\nres_model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate/10), metrics=['accuracy'])\nprint(\"Created model and loaded weights from file\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1, figsize = (7,10)) \n    \nplt.subplot(211)  \nplt.plot(res_history.history['accuracy']+res_history_final.history['accuracy'])  \nplt.plot(res_history.history['val_accuracy']+res_history_final.history['val_accuracy'])  \nplt.title('model accuracy with ResNet50 after fine-tuning')  \nplt.ylabel('accuracy')  \nplt.xlabel('epoch')\nplt.ylim(0.3,1.03)\nplt.legend(['train', 'valid']) \nplt.axvline(initial_epochs, c='C7', ls='--')\n    \nplt.subplot(212)  \nplt.plot(res_history.history['loss']+res_history_final.history['loss'])  \nplt.plot(res_history.history['val_loss']+res_history_final.history['val_loss'])  \nplt.title('model loss with ResNet50 after fine-tuning')  \nplt.ylabel('loss')  \nplt.xlabel('epoch')\nplt.legend(['train', 'valid']) \nplt.axvline(initial_epochs, c='C7', ls='--')\n\nplt.savefig('/kaggle/working/model_hurricane_resnet50_after_45epochs.png', bbox_inches='tight')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Making predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = res_model.predict_generator(test_generator,steps = STEP_SIZE_TEST)\n\npredicts = np.argmax(predictions, axis=1)\npd.Series(predicts).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true = [z for y in y_test for z in y]\npd.Series(y_true).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicts = pd.Series(predicts)\ny_true = pd.Series(y_true)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Model ResNet50 fine-tuned \\n\")\nprint(\"Precision\", precision_score(y_true, predicts, average=None), '\\n')\nprint(\"Recall\", recall_score(y_true, predicts, average=None), '\\n')\nprint(\"f1_score\", f1_score(y_true, predicts, average=None), '\\n')\nprint(\"confusion_matrix\")\nprint(confusion_matrix(y_true, predicts))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix = confusion_matrix(y_true, predicts)\ndf_cm = pd.DataFrame(matrix, \n  index = ['Not damaged', 'Flooded'],\n  columns = ['Not damaged', 'Flooded'])\n\nsns.heatmap(df_cm,annot=True,cbar=False, fmt='g', square=True)\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.title('Confusion Matrix of ResNet50 CNN')\n\n#plt.figure(figsize = (4,7))\n#plt.show()\nplt.savefig('/kaggle/working/confusion_matrix_resnet50.png', bbox_inches='tight')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_loss, val_accuracy = res_model.evaluate(validation_generator)\ntest_loss, test_accuracy = res_model.evaluate(test_generator)\n\nval_accuracy, test_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5,2))\nplt.title('Label distribution in unbalanced test data')\npd.DataFrame(y_test_plot)['label'].value_counts().plot(kind='barh')\nplt.savefig('/kaggle/working/distribution.png', bbox_inches='tight')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_plot = pd.DataFrame(y_test)\ny_test_plot.columns = ['label']\ny_test_plot.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ResNet152"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nresnet152_model = ResNet152(include_top = False, pooling = 'avg', weights='imagenet')\n\n# freeze the convolutional base\nresnet152_model.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(resnet152_model.layers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res152_model = Sequential()\n\nres152_model.add(resnet152_model)\nres152_model.add(Dense(1024,activation='relu')) #dense layer 2\nres152_model.add(Dropout(0.2))\nres152_model.add(Dense(128, activation='relu'))\nres152_model.add(Dropout(0.5))\nres152_model.add(Dense(num_classes, activation = 'softmax'))\n\nbase_learning_rate = 0.0001\nres152_model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nres152_model.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res152_history = res152_model.fit_generator(\n            train_generator,\n            steps_per_epoch=STEP_SIZE_TRAIN,\n            epochs=10,\n            validation_data=validation_generator,\n            validation_steps=STEP_SIZE_VALID)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# unfreeze the layers\nresnet152_model.trainable = True\n\n# let's take a look to see how many layers are in the base model\nprint(\"Number of layers in the pre-trained model: \", len(resnet152_model.layers))\n\n# fine-tune from this layer onwards\nfine_tune_at = 10\n\n# freeze all the layers before the `fine_tune_at` layer\nfor layer in resnet152_model.layers[:fine_tune_at]:\n  layer.trainable =  False\n\n#Recompile the model using a lower training rate:\n\nres152_model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate/10),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nres152_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"initial_epochs = 10\nfine_tune_epochs = 65\ntotal_epochs =  initial_epochs + fine_tune_epochs\n\n# checkpoint\nfilepath=\"/kaggle/working/ResNet152_weights.best.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]\n\n\nres152_history_final = res152_model.fit_generator(\n            train_generator,\n            epochs=total_epochs,\n            initial_epoch=res152_history.epoch[-1]+1,\n            validation_data=validation_generator,\n            validation_steps=STEP_SIZE_VALID,\n            callbacks=callbacks_list)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading weights"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load weights\nres152_model.load_weights(\"/kaggle/working/ResNet101_weights.best.hdf5\")\n# Compile model (required to make predictions)\nres152_model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate/10), metrics=['accuracy'])\nprint(\"Created model and loaded weights from file\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1, figsize = (7,10)) \n    \nplt.subplot(211)  \nplt.plot(res152_history.history['accuracy']+res152_history_final.history['accuracy'])  \nplt.plot(res152_history.history['val_accuracy']+res152_history_final.history['val_accuracy'])  \nplt.title('model accuracy with ResNet152 after fine-tuning')  \nplt.ylabel('accuracy')  \nplt.xlabel('epoch')\nplt.ylim(0.3,1.03)\nplt.legend(['train', 'valid']) \nplt.axvline(initial_epochs, c='C7', ls='--')\n    \nplt.subplot(212)  \nplt.plot(res152_history.history['loss']+res152_history_final.history['loss'])  \nplt.plot(res152_history.history['val_loss']+res152_history_final.history['val_loss'])  \nplt.title('model loss with ResNet152 after fine-tuning')  \nplt.ylabel('loss')  \nplt.xlabel('epoch')\nplt.legend(['train', 'valid']) \nplt.axvline(initial_epochs, c='C7', ls='--')\n\nplt.savefig('/kaggle/working/model_hurricane_resnet152_after_45epochs.png', bbox_inches='tight')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = res152_model.predict_generator(test_generator,steps = STEP_SIZE_TEST)\n\npredicts = np.argmax(predictions, axis=1)\npd.Series(predicts).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true = [z for y in y_test for z in y]\npd.Series(y_true).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicts = pd.Series(predicts)\ny_true = pd.Series(y_true)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Model ResNet101 fine-tuned on unbalanced Test \\n\")\nprint(\"Precision\", precision_score(y_true, predicts, average=None), '\\n')\nprint(\"Recall\", recall_score(y_true, predicts, average=None), '\\n')\nprint(\"f1_score\", f1_score(y_true, predicts, average=None), '\\n')\nprint(\"confusion_matrix\")\nprint(confusion_matrix(y_true, predicts))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix = confusion_matrix(y_true, predicts)\ndf_cm = pd.DataFrame(matrix, \n  index = ['Not damaged', 'Flooded'],\n  columns = ['Not damaged', 'Flooded'])\n\nsns.heatmap(df_cm,annot=True,cbar=False, fmt='g', square=True)\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.title('Confusion Matrix of ResNet152 model')\n\n#plt.figure(figsize = (4,7))\n#plt.show()\nplt.savefig('/kaggle/working/confusion_matrix_resnet101.png', bbox_inches='tight')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_loss, val_accuracy = res152_model.evaluate(validation_generator)\ntest_loss, test_accuracy = res152_model.evaluate(test_generator)\n\nval_accuracy, test_accuracy","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}